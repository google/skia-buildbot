load("@io_bazel_rules_go//go:def.bzl", "go_binary", "go_library")
load("@bazel_gazelle//:def.bzl", "gazelle")
load("@com_github_bazelbuild_buildtools//buildifier:def.bzl", "buildifier")
load("@io_bazel_rules_docker//container:container.bzl", "container_push")
load("@io_bazel_rules_docker//docker/util:run.bzl", "container_run_and_commit")
load("//:elements-sk-scss.bzl", "generate_tilde_prefixed_elements_sk_scss_files")

# Disable generation of go_proto_library targets. Let Gazelle use checked-in .pb.go files instead.
#
# We opt out of this feature for the following reasons:
#
# 1) Generated files are invisible to code editors and IDEs, which breaks features such as code
#    completion, automated refactors, etc. This can be fixed with editor plugins (see
#    https://github.com/bazelbuild/rules_go/issues/512), but none are available at this time.
#
# 2) Leveraging the preexisting, checked-in .pb.go is the fastest way to roll out Bazel as the build
#    system for our repository, and is the recommended approach for already established projects, or
#    for projects that also need to build with "go build". See
#    https://github.com/bazelbuild/rules_go/blob/master/proto/core.rst#option-2-use-pre-generated-pbgo-files.
#
# In the future, we might decide to leverage Gazelle's generation of go_proto_library rules. To
# address point 1) above, a potential approach is to check in any files generated via
# go_proto_library targets. This works because if there's a source file checked in the repository,
# and a build target that generates a file of the same name, Bazel will ignore the checked in file
# and use the generated file instead. To keep the checked in and generated files in sync, a rule
# such as generated_file_test can be used, as mentioned here:
# https://github.com/bazelbuild/rules_go/issues/512#issuecomment-747844469.
#
# Documentation for this directive: https://github.com/bazelbuild/bazel-gazelle#directives.
#
# gazelle:proto disable

# This directive tells Gazelle to use a custom macro instead of rules_go's go_test rule for any
# Gazelle-generated Go test targets.
#
# The custom macro generates separate go_test targets for manual Go tests, which will be tagged as
# manual. The macro relies on the assumption that any manual test cases will be placed on Go source
# files ending in "_manual_test.go". This convention is enforced by unittest.ManualTest(). If the
# test target does not contain any manual test, the custom macro behaves exactly like rules_go's
# go_test rule.
#
# See the macro's docstring for details.
#
# Documentation for this directive: https://github.com/bazelbuild/bazel-gazelle#directives.
#
# gazelle:map_kind go_test go_test //bazel/go:go_test.bzl

# gazelle:prefix go.skia.org/infra
gazelle(name = "gazelle")

exports_files(
    ["tsconfig.json"],
    visibility = ["//visibility:public"],
)

buildifier(
    name = "buildifier",
    exclude_patterns = ["./**/node_modules/*"],
    lint_mode = "warn",
)

#############################################################################
# Utility tool to extract screenshots taken by Puppeteer tests under Bazel. #
#############################################################################

# Wrapper script so we can invoke the tool from the workspace root, instead of the directory where
# the tool's go_binary target is located.
genrule(
    name = "extract_puppeteer_screenshots_wrapper_script",
    srcs = ["//puppeteer-tests/bazel/extract_puppeteer_screenshots"],
    outs = ["extract_puppeteer_screenshots.sh"],
    cmd = " && ".join([
        # The $@ variable holds the path to the genrule's only output file. The $$@ variable is the
        # shell's $@ variable ($-escaped), which is used here to pipe through to the underlying Go
        # program any command-line arguments passed to the wrapper shell script.
        #
        # See https://docs.bazel.build/versions/master/be/general.html#genrule.
        "echo '#!/bin/bash' >> $@",
        "echo '$(rootpath //puppeteer-tests/bazel/extract_puppeteer_screenshots) $$@' >> $@",
    ]),
)

# Usage: "bazel run //:extract_puppeteer_screenshots -- --output_dir=<output directory>".
sh_binary(
    name = "extract_puppeteer_screenshots",
    srcs = ["extract_puppeteer_screenshots.sh"],
    data = ["//puppeteer-tests/bazel/extract_puppeteer_screenshots"],
)

############################################
# Custom Remote Build Execution toolchain. #
############################################

# Generates a custom toolchain container for Remote Build Execution which extends the default RBE
# ubuntu16-04 container with any extra dependencies needed for Skia Infrastructure build targets.
#
# This container can be pushed to GCR via the container_push target defined below.
#
# To debug this image:
#
#     # Build the container image.
#     $ bazel build //:rbe_container_skia_infra
#
#     # Load the container.
#     $ docker load -i bazel-bin/rbe_container_skia_infra_commit.tar
#     Loaded image: bazel/default:rbe_container_skia_infra
#
#     # Run the container.
#     $ docker run -it bazel/default:rbe_container_skia_infra /bin/bash
#
# Notes:
#
#  - This target is tagged with "no-remote" because the container_run_and_commit rule calls the
#    Docker binary, which requires the Docker daemon to be running. This fails on RBE with error
#    "Cannot connect to the Docker daemon at [...]. Is the docker daemon running?". By tagging this
#    target with "no-remote", we tell Bazel to build this target locally, even with --config=remote.
#
#  - The output of this rule is a >3GB .tar with the container image, so this target can take
#    several minutes to build. This is OK because we only need to rebuild this container very
#    occasionally, and Bazel will cache the output artifact.
#
# Reference:
# https://cloud.google.com/remote-build-execution/docs/create-custom-toolchain#creating_a_custom_toolchain_container
container_run_and_commit(
    name = "rbe_container_skia_infra",
    commands = [
        # The add-apt-repository command does not work without fixing the python3 symlink first.
        "rm /usr/bin/python3",
        "ln -s /usr/bin/python3.5 /usr/bin/python3",

        # Install the add-apt-repository command, and other packages needed to fetch repositories.
        "apt-get update",
        "apt-get install -y software-properties-common apt-transport-https ca-certificates gnupg",

        # Add the Chrome repository.
        "curl -fsSL https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -",
        "add-apt-repository 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main'",
        "apt-get update",

        # Install Chrome and fonts to support major charsets.
        #
        # This is necessary for the karma_test rule to work, which runs web tests on a headless
        # Chrome, and also for the bundled version of Chromium that Puppeteer installs to
        # render fonts properly.
        #
        # Adapted from:
        # https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md#running-puppeteer-in-docker
        "apt-get install -y " + " ".join([
            "google-chrome-stable",
            "fonts-ipafont-gothic",
            "fonts-wqy-zenhei",
            "fonts-thai-tlwg",
            "fonts-kacst",
            "fonts-freefont-ttf",
            # Prevent "error while loading shared libraries: libXss.so.1" in Puppeteer tests.
            # See https://github.com/puppeteer/puppeteer/issues/6192.
            "libxss1",
        ]),

        # Add the Google Cloud SDK repository as per the instructions here:
        # https://cloud.google.com/sdk/docs/install#deb.
        "echo 'deb [signed-by=/usr/share/keyrings/cloud.google.gpg] " +
        "      https://packages.cloud.google.com/apt cloud-sdk main'" +
        " | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list",
        "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg" +
        " | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -",
        "apt-get update",

        # Install the Google Cloud SDK and emulators.
        "apt-get install -y " + " ".join([
            "google-cloud-sdk",
            "google-cloud-sdk-bigtable-emulator",
            "google-cloud-sdk-datastore-emulator",
            "google-cloud-sdk-firestore-emulator",
            "google-cloud-sdk-pubsub-emulator",
        ]),

        # Install CockroachDB as per the instructions here:
        # https://www.cockroachlabs.com/docs/v20.2/install-cockroachdb-linux.
        "wget -qO- https://binaries.cockroachdb.com/cockroach-v20.2.4.linux-amd64.tgz | tar xvz",
        "cp -i cockroach-v20.2.4.linux-amd64/cockroach /usr/local/bin/",

        # Install depot_tools, necessary to pull binaries via CIPD.
        "git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git /depot_tools",

        # Remove the Git distribution included in the base image. We'll install our own from CIPD.
        # The Git CLI is invoked from some tests.
        "apt-get remove git -y",

        # Initialize the CIPD root directory.
        "mkdir /cipd",
        "/depot_tools/cipd init /cipd -force",

        # Install CIPD packages needed by various tests. These should be kept in sync with
        # //cipd.ensure.
        "/depot_tools/cipd install infra/3pp/tools/git/linux-amd64 version:2.29.2.chromium.6 " +
        "    -root /cipd",
        "/depot_tools/cipd install infra/tools/luci/isolate/linux-amd64 " +
        "    git_revision:14be8b751c0fb567535f520f8a7bc60c3f40b378 -root /cipd",
        "/depot_tools/cipd install infra/tools/luci/isolated/linux-amd64 " +
        "    git_revision:14be8b751c0fb567535f520f8a7bc60c3f40b378 -root /cipd",

        # Include the CIPD-installed binaries in the PATH. Note that this does not persist after
        # the container is created. Said binaries are included in the PATH during testing via a
        # --test_env flag defined in //.bazelrc.
        "export PATH=$PATH:/cipd:/cipd/bin",

        # Create a default Git user. This is necessary for some Git tests to pass.
        "mkdir /cipd/etc",  # The below commands fail unless this directory exists.
        "git config --system user.name 'Bazel RBE Test User'",
        "git config --system user.email 'bazel-rbe-test-user@example.com'",
    ],
    image = "@rbe_ubuntu1604//image",
    tags = [
        "manual",  # Exclude it from wildcard queries, e.g. "bazel build //...".
        "no-remote",
    ],
)

# This target can be used to upload the custom RBE container toolchain to GCR. It will be available
# as gcr.io/skia-public/rbe-container-skia-infra.
#
# Note: this can take several minutes to finish because it will upload a >3GB .tar file to GCR.
container_push(
    name = "push_rbe_container_skia_infra",
    format = "Docker",
    image = ":rbe_container_skia_infra_commit.tar",  # Generated by :rbe_container_skia_infra.
    registry = "gcr.io",
    repository = "skia-public/rbe-container-skia-infra",
    tag = "{STABLE_DOCKER_TAG}",
    tags = [
        "manual",  # Exclude it from wildcard queries, e.g. "bazel build //...".
        "no-remote",  # We cannot build :rbe_container_skia_infra on RBE.
    ],
)

# Generate a copy of the elements-sk SCSS stylesheets under //bazel-bin/~elements-sk for
# compatibility with Webpack-style tilde-prefixed SCSS imports. See the macro docstring for details.
generate_tilde_prefixed_elements_sk_scss_files(
    name = "~elements-sk",
)

go_library(
    name = "infra_lib",
    srcs = ["run_unittests.go"],
    importpath = "go.skia.org/infra",
    visibility = ["//visibility:private"],
    deps = [
        "//go/common",
        "//go/git",
        "//go/skerr",
        "//go/sklog",
        "//go/testutils/unittest",
        "//go/timer",
        "//go/util",
    ],
)

go_binary(
    name = "infra",
    embed = [":infra_lib"],
    visibility = ["//visibility:public"],
)
